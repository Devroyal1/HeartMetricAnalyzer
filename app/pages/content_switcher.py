content_switcher = {
    "Naive Bayes": "Naive Bayes is a classification technique based on Bayes' Theorem with an assumption of independence among predictors. A Naive Bayes classifier assumes that the presence of a particular feature in a class is unrelated to the presence of any other feature.",
    "K-Nearest Neighbors": "K-Nearest Neighbors is a simple, easy-to-implement supervised machine learning algorithm that can be used to solve both classification and regression problems.",
    "Support Vector Machines": "Support Vector Machines is a supervised machine learning algorithm that can be used for both classification or regression challenges. However, it is mostly used in classification problems.",
    "Multilayer Perceptron": "Multilayer Perceptron is a class of feedforward artificial neural network. An MLP consists of at least three layers of nodes: an input layer, a hidden layer, and an output layer.",
    "Gradient Boosting": "Gradient Boosting is a machine learning technique for regression and classification problems, which produces a prediction model in the form of an ensemble of weak prediction models, typically decision trees.",
    "Random Forest": "Random Forest is an ensemble learning method for classification, regression, and other tasks that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes of the individual trees.",
    "Decision Tree": "Decision Tree is a flowchart-like tree structure where an internal node represents a feature(or attribute), the branch represents a decision rule, and each leaf node represents the outcome.",
    "Logistic Regression": "Logistic Regression is a statistical model that in its basic form uses a logistic function to model a binary dependent variable."
}